{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PanoGAN_Raw.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diviramon/BASSic/blob/master/PanoGAN_Raw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7zy0qm4qrci",
        "outputId": "c406bad3-11cb-4f8e-ec01-c6970f519050"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar  7 19:20:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi37gsnXq6dh",
        "outputId": "6174a565-045d-42c2-d280-f2ee7a5f2bca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qqc8FvuMVBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e287a08-2215-49e8-91eb-45c92b9aeff1"
      },
      "source": [
        "!pip install pydicom\n",
        "!pip install pytorch-msssim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/15/df16546bc59bfca390cf072d473fb2c8acd4231636f64356593a63137e55/pydicom-2.1.2-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 12.6MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.1.2\n",
            "Collecting pytorch-msssim\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/d3/3cb0f397232cf79e1762323c3a8862e39ad53eca0bb5f6be9ccc8e7c070e/pytorch_msssim-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-msssim) (1.7.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (1.19.5)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lW9VN4GBSr3"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SgV287Q7i4"
      },
      "source": [
        "DIM = 64\n",
        "OUTPUT_DIM = DIM*DIM*1\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import cv2\n",
        "import re\n",
        "import random\n",
        "from skimage.io import imread \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.autograd import grad\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import random_split, ConcatDataset\n",
        "\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, average_precision_score, f1_score\n",
        "from scipy.optimize import brentq\n",
        "from scipy.interpolate import interp1d\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pydicom as dcm\n",
        "from skimage import io, exposure\n",
        "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import autograd\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import sampler\n",
        "from argparse import ArgumentParser\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-uHk07CBVK5"
      },
      "source": [
        "# Make Folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ1w65QGS-dm"
      },
      "source": [
        "!rm -r sample_data/\n",
        "!mkdir data\n",
        "!mkdir data/train\n",
        "!mkdir data/train/healthy\n",
        "!mkdir data/valid\n",
        "!mkdir data/valid/healthy\n",
        "!mkdir data/valid/nodule\n",
        "!mkdir data/test/\n",
        "!mkdir data/test/healthy\n",
        "!mkdir data/test/nodule\n",
        "!mkdir data/patients/\n",
        "!mkdir output/\n",
        "!mkdir output/patients/\n",
        "\n",
        "!mkdir encoder"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UuoCc3eBXQa"
      },
      "source": [
        "# Read Image Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6ev8OpNLXKr"
      },
      "source": [
        "\n",
        "def read_indiana(file_name, cxr_path, mask_path):\n",
        "  \n",
        "  dcm_filename = file_name[3:-4] + '.dcm'\n",
        "\n",
        "  # Pre-process mask\n",
        "  mask = cv2.imread(os.path.join(mask_path, file_name))\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "  mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
        "  mask = (mask > 127) * 255\n",
        "\n",
        "  # Read in DICOM \n",
        "  ds = dcm.dcmread(os.path.join(cxr_path, dcm_filename))\n",
        "  cxr = ds.pixel_array\n",
        "  cxr = cv2.resize(cxr, (1024, 1024))  \n",
        "  normalizedImg = np.zeros((1024, 1024))\n",
        "  cxr = cv2.normalize(cxr,  normalizedImg, 0, 255, cv2.NORM_MINMAX,0)\n",
        "  if ds.PhotometricInterpretation == 'MONOCHROME1':\n",
        "      cxr = 255 - cxr\n",
        "\n",
        "  return mask, cxr"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODytx0lWLXxp"
      },
      "source": [
        "def read_nih(file_name, cxr_path, mask_path):\n",
        "  \n",
        "  # Pre-process mask\n",
        "  mask = cv2.imread(os.path.join(mask_path, file_name))\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "  mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
        "  mask = (mask > 127) * 255\n",
        "  \n",
        "  # Read in PNG\n",
        "  cxr = cv2.imread(os.path.join(cxr_path, file_name))\n",
        "  cxr = cv2.cvtColor(cxr, cv2.COLOR_BGR2GRAY)\n",
        "  cxr = cv2.resize(cxr, (1024, 1024)) \n",
        "  normalizedImg = np.zeros((1024, 1024))\n",
        "  cxr = cv2.normalize(cxr,  normalizedImg, 0, 255, cv2.NORM_MINMAX,0)\n",
        "\n",
        "  return mask, cxr"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD5nusdNLaW8"
      },
      "source": [
        "def read_jsrt(file_name, cxr_path, mask_path):\n",
        "\n",
        "  # Pre-process mask\n",
        "  mask = cv2.imread(os.path.join(mask_path, file_name))\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "  mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
        "  mask = (mask > 127) * 255\n",
        "\n",
        "  # Read in IMG\n",
        "  # fname = file_name[:-4] + '.IMG'\n",
        "  # cxr = 1.0 - np.fromfile(os.path.join(cxr_path, fname), dtype='>u2').reshape((2048, 2048)) * 1. / 4095\n",
        "  cxr = cv2.imread(os.path.join(cxr_path, file_name))\n",
        "  cxr = cv2.cvtColor(cxr, cv2.COLOR_BGR2GRAY)\n",
        "  cxr = cv2.resize(cxr, (1024, 1024)) \n",
        "  normalizedImg = np.zeros((1024, 1024))\n",
        "  cxr = cv2.normalize(cxr,  normalizedImg, 0, 255, cv2.NORM_MINMAX,0)\n",
        "\n",
        "  return mask, cxr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNXphgg8Lb3O"
      },
      "source": [
        "def crop_patches(image, mask, total_patches, box, image_name, dataset, svpath):\n",
        "  if dataset == 'indiana':\n",
        "    patch_extractor = ExtractPatches(image_name, image, mask, box, DIM, DIM//2, dataset, svpath)\n",
        "  else:\n",
        "    patch_extractor = ExtractPatches(image_name, image, mask, box, DIM, DIM//4, dataset, svpath)\n",
        "  \n",
        "  lung_area = np.count_nonzero(mask)\n",
        "  patches = patch_extractor.extract_all_patches()\n",
        "  total_patches = total_patches + patches\n",
        "\n",
        "  return total_patches"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLQTelfzLdvf"
      },
      "source": [
        "class ExtractPatches:\n",
        "    def __init__(self, image_name, image, mask, bbox, patchSize, stride, dataset, out_path):\n",
        "        self.image = image\n",
        "        self.out_path = out_path\n",
        "        self.dataset = dataset\n",
        "        self.bbox = bbox\n",
        "        self.annotated = np.copy(image) \n",
        "        self.reconstructed = np.empty(image.shape)\n",
        "        self.reconstructed[:] = np.nan\n",
        "        self.image_name = image_name\n",
        "        self.patchSize = patchSize\n",
        "        self.stride = stride\n",
        "        self.mask = mask\n",
        "\n",
        "    def draw_single_patches(self, coords, patch):\n",
        "      y1 = coords[0] * self.stride\n",
        "      x1 = coords[1] * self.stride\n",
        "      y2 = coords[0] * self.stride + self.patchSize\n",
        "      x2 = coords[1] * self.stride + self.patchSize\n",
        "      self.annotated = cv2.rectangle(self.annotated,(x1,y1), (x2,y2), (0, 0, 255))\n",
        "      self.reconstructed[y1:y2, x1:x2] = patch\n",
        "    \n",
        "    def extract_single_patches(self, patch):\n",
        "        croppedPatches = self.image[(patch[0] * self.stride):(patch[0] * self.stride + self.patchSize), \n",
        "                               (patch[1] * self.stride):(patch[1] * self.stride + self.patchSize)]\n",
        "        return croppedPatches\n",
        "\n",
        "    def no_of_patches(self):\n",
        "        yNoOfPatches, xNoOfPatches = (int((self.image.shape[1] - self.patchSize) / self.stride + 1),\n",
        "                                      int((self.image.shape[0] - self.patchSize) / self.stride + 1))\n",
        "        return xNoOfPatches, yNoOfPatches\n",
        "\n",
        "    def extract_all_patches(self):\n",
        "        xNoOfPatches, yNoOfPatches = self.no_of_patches()\n",
        "        closest = None\n",
        "        closest_dist = 10000\n",
        "\n",
        "        allPatches = list()\n",
        "        for y in range(yNoOfPatches):\n",
        "            for x in range(xNoOfPatches):\n",
        "              patch = self.extract_single_patches((x,y))\n",
        "                            \n",
        "              y1 = x * self.stride\n",
        "              x1 = y * self.stride\n",
        "              y2 = x * self.stride + self.patchSize\n",
        "              x2 = y * self.stride + self.patchSize\n",
        "              mask_cover = np.sum(self.mask[y1:y2, x1:x2])\n",
        "              if x1 > 0 and x2 < 1024 and y1 > 0 and y2 < 1024:\n",
        "                if patch.shape[0] == self.patchSize and patch.shape[1] and mask_cover/(255*self.patchSize*self.patchSize) > 0.75:\n",
        "                  if self.dataset == 'jsrt-nodule':\n",
        "                      cx = self.bbox[0]\n",
        "                      cy = self.bbox[1]\n",
        "                      if (x1 < cx) and (x2 > cx) and (y1 < cy) and (y2 > cy):\n",
        "                          bbox_cx = (x1+x2)//2\n",
        "                          bbox_cy = (y1+y2)//2\n",
        "                          if ((bbox_cx-cx)**2 + (bbox_cy-cy)**2) < closest_dist:\n",
        "                              closest_dist = (bbox_cx-cx)**2 + (bbox_cy-cy)**2\n",
        "                              closest = patch\n",
        "                              closest_x = x\n",
        "                              closest_y = y\n",
        "                          self.draw_single_patches((x,y), patch)\n",
        "                  elif self.dataset == 'nih-nodule':\n",
        "                      cx = (self.bbox[0] + self.bbox[2])//2\n",
        "                      cy = (self.bbox[1] + self.bbox[3])//2\n",
        "                      if (x1 < cx) and (x2 > cx) and (y1 < cy) and (y2 > cy):\n",
        "                          bbox_cx = (x1+x2)//2\n",
        "                          bbox_cy = (y1+y2)//2\n",
        "                          if ((bbox_cx-cx)**2 + (bbox_cy-cy)**2) < closest_dist:\n",
        "                              closest_dist = (bbox_cx-cx)**2 + (bbox_cy-cy)**2\n",
        "                              closest = patch\n",
        "                              closest_x = x\n",
        "                              closest_y = y\n",
        "                          self.draw_single_patches((x,y), patch)\n",
        "                  else:\n",
        "                      allPatches.append(patch)\n",
        "                      cv2.imwrite(self.out_path + str(x) + '_' + str(y) + '_' + self.image_name, patch)\n",
        "                      # plt.imsave(self.out_path + str(x) + '_' + str(y) + '_' + self.image_name, patch, cmap='gray')\n",
        "                      self.draw_single_patches((x,y), patch)\n",
        "        \n",
        "        if closest is not None:\n",
        "            allPatches.append(closest)\n",
        "            cv2.imwrite(self.out_path + str(closest_x) + '_' + str(closest_y) + '_' + self.image_name, closest)\n",
        "            # plt.imsave(self.out_path + str(closest_x) + '_' + str(closest_y) + '_' + self.image_name, closest, cmap='gray')\n",
        "\n",
        "        #cv2_imshow(self.annotated)\n",
        "\n",
        "        return allPatches"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysRjrn3yBc15"
      },
      "source": [
        "# Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tefDiouvLflW"
      },
      "source": [
        "jsrt_mask_path = '/content/drive/MyDrive/FYDP 2021/JSRT Data/JSRT Masks'\n",
        "jsrt_cxr_path = '/content/drive/MyDrive/FYDP 2021/JSRT Data/JSRT Images'\n",
        "\n",
        "nih_healthy_mask_path = '/content/drive/MyDrive/FYDP 2021/NIH-Data/Healthy_masks'\n",
        "nih_healthy_cxr_path = '/content/drive/MyDrive/FYDP 2021/NIH-Data/Healthy_raw'\n",
        "\n",
        "nih_nodule_mask_path = '/content/drive/MyDrive/FYDP 2021/NIH-Data/Nodule_masks'\n",
        "nih_nodule_cxr_path = '/content/drive/MyDrive/FYDP 2021/NIH-Data/Nodule_raw'\n",
        "\n",
        "indiana_mask_path = '/content/drive/My Drive/FYDP 2021/Indiana University Database/Additional Masks'\n",
        "indiana_cxr_path = '/content/drive/My Drive/FYDP 2021/Indiana University Database/DICOM Frontal'\n",
        "\n",
        "nih_healthy_img_list = os.listdir(nih_healthy_mask_path)\n",
        "indiana_img_list = os.listdir(indiana_mask_path)\n",
        "\n",
        "nih_info = pd.read_csv('/content/drive/MyDrive/FYDP 2021/NIH-Data/BBox_List_2017.csv')\n",
        "nih_info = nih_info[nih_info['Finding Label']=='Nodule']\n",
        "nih_nodule_list = nih_info['Image Index'].values\n",
        "\n",
        "jsrt_info = pd.read_csv('/content/drive/MyDrive/FYDP 2021/JSRT Data/jsrt_metadata (1).csv')\n",
        "jsrt_healthy_info = jsrt_info[jsrt_info['state']=='non-nodule']\n",
        "jsrt_healthy_list = jsrt_healthy_info['study_id'].values\n",
        "jsrt_nodule_info = jsrt_info[jsrt_info['state']!='non-nodule']\n",
        "jsrt_nodule_list = jsrt_nodule_info['study_id'].values\n",
        "\n",
        "batchsize = 64\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG0CQWQ2BeoR"
      },
      "source": [
        "# Load Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrd3ASF0Bhs8"
      },
      "source": [
        "### Indiana"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6S410tvLv3t",
        "outputId": "5bf00f89-6ef6-4eac-96f1-33588084d5cf"
      },
      "source": [
        "total_patches = []\n",
        "for j in range(len(indiana_img_list)):\n",
        "    image_name = indiana_img_list[j]\n",
        "    #print(image_name)\n",
        "    box = []\n",
        "    mask, cxr = read_indiana(image_name, indiana_cxr_path, indiana_mask_path)\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'indiana', 'data/train/healthy/')\n",
        "len(total_patches)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RUXmHDRBjgQ"
      },
      "source": [
        "### NIH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTI57h0VLxPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d705ab15-8053-4f00-81de-7a230e62d7cb"
      },
      "source": [
        "total_patches = []\n",
        "for j in range(len(nih_healthy_img_list)):\n",
        "    image_name = nih_healthy_img_list[j]\n",
        "    #print(image_name)\n",
        "    box = []\n",
        "    mask, cxr = read_nih(image_name, nih_healthy_cxr_path, nih_healthy_mask_path)\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'nih-healthy', 'data/valid/healthy/')\n",
        "len(total_patches)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKWa5njFLy7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8a17a5-3000-4df4-90eb-22f0434808d6"
      },
      "source": [
        "total_patches = []\n",
        "for j in range(len(nih_nodule_list)):\n",
        "    image_name = nih_nodule_list[j]\n",
        "    #print(image_name)\n",
        "    bx = nih_info['Bbox [x'].values[j]\n",
        "    by = nih_info['y'].values[j]\n",
        "    bh = nih_info['h]'].values[j]\n",
        "    bw = nih_info['w'].values[j]\n",
        "    box = [bx,by, bx+bw, by+bh]\n",
        "    mask, cxr = read_nih(image_name, nih_nodule_cxr_path, nih_nodule_mask_path)\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'nih-nodule', 'data/valid/nodule/')\n",
        "len(total_patches)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPcE_L6gL01i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff32e1e4-9435-4a65-d793-87374b3c4066"
      },
      "source": [
        "files = os.listdir(path='data/valid/healthy')\n",
        "nfiles = len(files) + len(os.listdir(\"data/valid/nodule\"))\n",
        "if nfiles % batchsize != 0:\n",
        "  del_files = random.sample(files,nfiles%batchsize)\n",
        "  for dfile in del_files:\n",
        "    os.remove(os.path.join(\"data/valid/healthy/\", dfile))\n",
        "  print(\"Files removed: \", len(del_files))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files removed:  59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soT_7J9A2gm5"
      },
      "source": [
        "## JSRT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QLU_-pL2jOo"
      },
      "source": [
        "total_patches = []\r\n",
        "for j in range(len(jsrt_nodule_list)):\r\n",
        "    image_name = jsrt_nodule_list[j]\r\n",
        "    #print(image_name)\r\n",
        "    bx = jsrt_nodule_info['x'].values[j]/2\r\n",
        "    by = jsrt_nodule_info['y'].values[j]/2\r\n",
        "    box = [bx,by]\r\n",
        "    mask, cxr = read_jsrt(image_name, jsrt_cxr_path, jsrt_mask_path)\r\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'jsrt-nodule', 'data/test/nodule/')\r\n",
        "len(total_patches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go-B3imW2o6q"
      },
      "source": [
        "total_patches = []\r\n",
        "jsrt_healthy_list = list(jsrt_healthy_list)\r\n",
        "\r\n",
        "for j in range(len(jsrt_healthy_list)):\r\n",
        "    image_name = jsrt_healthy_list[j]\r\n",
        "    print(image_name)\r\n",
        "    box = []\r\n",
        "    mask, cxr = read_jsrt(image_name, jsrt_cxr_path, jsrt_mask_path)\r\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'jsrt-healthy', 'data/test/healthy/')\r\n",
        "len(total_patches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM4yo_qd3Z4o"
      },
      "source": [
        "files = os.listdir(path='data/test/healthy')\r\n",
        "nfiles = len(files) + len(os.listdir(\"data/test/nodule\"))\r\n",
        "if nfiles % batchsize != 0:\r\n",
        "  del_files = random.sample(files,nfiles%batchsize)\r\n",
        "  for dfile in del_files:\r\n",
        "    os.remove(os.path.join(\"data/test/healthy/\", dfile))\r\n",
        "  print(\"Files removed: \", len(del_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS2lz0v7BmJd"
      },
      "source": [
        "# NN Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikmAgOieRDpv"
      },
      "source": [
        "class MyConvo2d(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init=True,  stride=1, bias=True):\n",
        "        super(MyConvo2d, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.padding = int((kernel_size - 1)/2)\n",
        "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size,\n",
        "                              stride=1, padding=self.padding, bias=bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GMjSW7YRG1W"
      },
      "source": [
        "class ConvMeanPool(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init=True):\n",
        "        super(ConvMeanPool, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim,\n",
        "                              kernel_size, he_init=self.he_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        output = (output[:, :, ::2, ::2] + output[:, :, 1::2, ::2] +\n",
        "                  output[:, :, ::2, 1::2] + output[:, :, 1::2, 1::2]) / 4\n",
        "        return output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1kH5oKKRJYn"
      },
      "source": [
        "class MeanPoolConv(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init=True):\n",
        "        super(MeanPoolConv, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim,\n",
        "                              kernel_size, he_init=self.he_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = (output[:, :, ::2, ::2] + output[:, :, 1::2, ::2] +\n",
        "                  output[:, :, ::2, 1::2] + output[:, :, 1::2, 1::2]) / 4\n",
        "        output = self.conv(output)\n",
        "        return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28YhPArqRMs5"
      },
      "source": [
        "class DepthToSpace(nn.Module):\n",
        "    def __init__(self, block_size):\n",
        "        super(DepthToSpace, self).__init__()\n",
        "        self.block_size = block_size\n",
        "        self.block_size_sq = block_size*block_size\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input.permute(0, 2, 3, 1)\n",
        "        (batch_size, input_height, input_width, input_depth) = output.size()\n",
        "        output_depth = int(input_depth / self.block_size_sq)\n",
        "        output_width = int(input_width * self.block_size)\n",
        "        output_height = int(input_height * self.block_size)\n",
        "        t_1 = output.reshape(batch_size, input_height,\n",
        "                             input_width, self.block_size_sq, output_depth)\n",
        "        spl = t_1.split(self.block_size, 3)\n",
        "        stacks = [t_t.reshape(batch_size, input_height,\n",
        "                              output_width, output_depth) for t_t in spl]\n",
        "        output = torch.stack(stacks, 0).transpose(0, 1).permute(0, 2, 1, 3, 4).reshape(\n",
        "            batch_size, output_height, output_width, output_depth)\n",
        "        output = output.permute(0, 3, 1, 2)\n",
        "        return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BmPaG7qROvE"
      },
      "source": [
        "class UpSampleConv(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init=True, bias=True):\n",
        "        super(UpSampleConv, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim,\n",
        "                              kernel_size, he_init=self.he_init, bias=bias)\n",
        "        self.depth_to_space = DepthToSpace(2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = torch.cat((output, output, output, output), 1)\n",
        "        output = self.depth_to_space(output)\n",
        "        output = self.conv(output)\n",
        "        return output"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rQAeQLGRQgy"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, resample=None, hw=DIM):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.resample = resample\n",
        "        self.bn1 = None\n",
        "        self.bn2 = None\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "        if resample == 'down':\n",
        "            self.bn1 = nn.LayerNorm([input_dim, hw, hw])\n",
        "            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n",
        "        elif resample == 'up':\n",
        "            self.bn1 = nn.BatchNorm2d(input_dim)\n",
        "            self.bn2 = nn.BatchNorm2d(output_dim)\n",
        "        elif resample == 'custom':\n",
        "            self.bn1 = nn.InstanceNorm2d(input_dim)\n",
        "            self.bn2 = nn.InstanceNorm2d(output_dim)\n",
        "        else:\n",
        "            raise Exception('invalid resample value')\n",
        "\n",
        "        if resample == 'down':\n",
        "            self.conv_shortcut = MeanPoolConv(\n",
        "                input_dim, output_dim, kernel_size=1, he_init=False)\n",
        "            self.conv_1 = MyConvo2d(\n",
        "                input_dim, input_dim, kernel_size=kernel_size, bias=False)\n",
        "            self.conv_2 = ConvMeanPool(\n",
        "                input_dim, output_dim, kernel_size=kernel_size)\n",
        "        elif resample == 'up':\n",
        "            self.conv_shortcut = UpSampleConv(\n",
        "                input_dim, output_dim, kernel_size=1, he_init=False)\n",
        "            self.conv_1 = UpSampleConv(\n",
        "                input_dim, output_dim, kernel_size=kernel_size, bias=False)\n",
        "            self.conv_2 = MyConvo2d(\n",
        "                output_dim, output_dim, kernel_size=kernel_size)\n",
        "        elif resample == \"custom\":\n",
        "            self.conv_shortcut = MeanPoolConv(\n",
        "                input_dim, output_dim, kernel_size=1, he_init=False)\n",
        "            self.conv_1 = MyConvo2d(\n",
        "                input_dim, input_dim, kernel_size=kernel_size, bias=False)\n",
        "            self.conv_2 = ConvMeanPool(\n",
        "                input_dim, output_dim, kernel_size=kernel_size)\n",
        "        else:\n",
        "            raise Exception('invalid resample value')\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.input_dim == self.output_dim and self.resample == None:\n",
        "            shortcut = input\n",
        "        else:\n",
        "            shortcut = self.conv_shortcut(input)\n",
        "\n",
        "        output = input\n",
        "        output = self.bn1(output)\n",
        "        output = self.relu1(output)\n",
        "        output = self.conv_1(output)\n",
        "        output = self.bn2(output)\n",
        "        output = self.relu2(output)\n",
        "        output = self.conv_2(output)\n",
        "\n",
        "        return shortcut + output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT-34TZ7RTq7"
      },
      "source": [
        "class ReLULayer(nn.Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(ReLULayer, self).__init__()\n",
        "        self.n_in = n_in\n",
        "        self.n_out = n_out\n",
        "        self.linear = nn.Linear(n_in, n_out)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.linear(input)\n",
        "        output = self.relu(output)\n",
        "        return output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqrKQAfCRWQt"
      },
      "source": [
        "class FCGenerator(nn.Module):\n",
        "    def __init__(self, FC_DIM=512):\n",
        "        super(FCGenerator, self).__init__()\n",
        "        self.relulayer1 = ReLULayer(128, FC_DIM)\n",
        "        self.relulayer2 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.relulayer3 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.relulayer4 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.linear = nn.Linear(FC_DIM, OUTPUT_DIM)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.relulayer1(input)\n",
        "        output = self.relulayer2(output)\n",
        "        output = self.relulayer3(output)\n",
        "        output = self.relulayer4(output)\n",
        "        output = self.linear(output)\n",
        "        output = self.tanh(output)\n",
        "        return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F4VC2MgReYU"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dim, output_dim, drop_rate=0.0):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(drop_rate)\n",
        "        self.conv_in = nn.Conv2d(1, dim, 3, 1, padding=1)\n",
        "        self.res1 = ResidualBlock(dim, dim*2, 3, 'down', DIM)\n",
        "        self.res2 = ResidualBlock(dim*2, dim*4, 3, 'down', int(DIM/2))\n",
        "        self.res3 = ResidualBlock(dim*4, dim*8, 3, 'down', int(DIM/4))\n",
        "        self.res4 = ResidualBlock(dim*8, dim*8, 3, 'down', int(DIM/8))\n",
        "        self.fc = nn.Linear(4*4*8*dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.dropout(x)\n",
        "        x = self.conv_in(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        x = self.res3(x)\n",
        "        x = self.res4(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(self.fc(x))\n",
        "        return torch.tanh(x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EboMTn_QwP0"
      },
      "source": [
        "from pytorch_msssim import ssim\r\n",
        "\r\n",
        "def ssim_loss(input,target,size_average=True):\r\n",
        "    input = (input + 1) / 2\r\n",
        "    target = (target + 1) / 2\r\n",
        "    ssim_loss = 1 - ssim(input, target, data_range=1, size_average=size_average)\r\n",
        "    return ssim_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpJsmaNXBrjx"
      },
      "source": [
        "# Flags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovVXOcHARgTp"
      },
      "source": [
        "import sys\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "device = torch.device('cuda:{}'.format(0))\n",
        "torch.cuda.set_device('cuda:{}'.format(0))\n",
        "MODE = 'wgan-gp'  # Valid options are dcgan, wgan, or wgan-gp\n",
        "DIM = 64  # This overfits substantially; you're probably better off with 64\n",
        "LAMBDA = 10  # Gradient penalty lambda hyperparameter\n",
        "CRITIC_ITERS = 5  # How many critic iterations per generator iteration\n",
        "BATCH_SIZE = batchsize  # Batch size\n",
        "ITERS = 100000  # How many generator iterations to train for\n",
        "OUTPUT_DIM = 1 * DIM * DIM  # Number of pixels in image (3*64*64)\n",
        "NOISE_SIZE = 512\n",
        "\n",
        "train_data_path = \"data/train/\"\n",
        "valid_data_path = \"data/valid/\"\n",
        "test_data_path = \"data/test/\"\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.determinstic = False\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdXhqA8KRz_G"
      },
      "source": [
        "def calc_gradient_penalty(netD, real_data, fake_data):\n",
        "    alpha = torch.rand(BATCH_SIZE, 1)\n",
        "    alpha = alpha.expand(BATCH_SIZE, int(real_data.nelement()/BATCH_SIZE)).contiguous()\n",
        "    alpha = alpha.view(BATCH_SIZE, 1, DIM, DIM)\n",
        "    alpha = alpha.to(device)\n",
        "\n",
        "    fake_data = fake_data.view(BATCH_SIZE, 1, DIM, DIM)\n",
        "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
        "\n",
        "    interpolates = interpolates.to(device)\n",
        "    interpolates.requires_grad_(True)\n",
        "\n",
        "    disc_interpolates = netD(interpolates)\n",
        "\n",
        "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=torch.ones(\n",
        "                                  disc_interpolates.size()).to(device),\n",
        "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
        "    return gradient_penalty"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux_cOKIaBvIp"
      },
      "source": [
        "# DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37O01eVmMnUH"
      },
      "source": [
        "def get_dataloaders(train_data_path, test_data_path, bs=batchsize):\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.RandomAffine(5, translate=[0.05,0.05]),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "    ])\n",
        "    \n",
        "    trn_dataset = datasets.ImageFolder(root=train_data_path, transform=test_transform)\n",
        "    tst_dataset = datasets.ImageFolder(root=test_data_path, transform=test_transform)\n",
        "\n",
        "    trn_loader = torch.utils.data.DataLoader(trn_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
        "    tst_loader = torch.utils.data.DataLoader(tst_dataset, batch_size=bs, shuffle=False)\n",
        "  \n",
        "    return trn_loader, tst_loader"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIk3JNRV28Fw"
      },
      "source": [
        "# PGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1--0gw512-jG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112233b5-1807-4307-984c-3775792fb9d3"
      },
      "source": [
        "!git clone https://nitishbhatt56:@github.com/nitishbhatt56/pytorch_GAN_zoo.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pytorch_GAN_zoo' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDeyy26C25H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ffec27-7fca-4457-ecd4-74218d6424b5"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/FYDP 2021/ANOGAN-Weights/PanoGAN/PGAN-p64-l512-raw-s4-i96.zip\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/FYDP 2021/ANOGAN-Weights/PanoGAN/PGAN-p64-l512-raw-s4-i96.zip\n",
            "replace output_networks/default/default_train_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjwCiFCW3DMP"
      },
      "source": [
        "import pytorch_GAN_zoo.models.utils.utils as utils\r\n",
        "import json\r\n",
        "import sys\r\n",
        "sys.path.insert(0,'./pytorch_GAN_zoo')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9odjZbo4FcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4b783c-407f-489d-cfaa-150303e7c958"
      },
      "source": [
        "checkpt_dir = 'output_networks'\r\n",
        "name='default'\r\n",
        "checkPointDir = os.path.join(checkpt_dir, name)\r\n",
        "module = 'PGAN'\r\n",
        "\r\n",
        "checkpointData = utils.getLastCheckPoint(\r\n",
        "            checkPointDir, name, scale=None, iter=None)\r\n",
        "\r\n",
        "print(checkpointData)\r\n",
        "modelConfig, pathModel, _ = checkpointData\r\n",
        "with open(modelConfig, 'rb') as file:\r\n",
        "    configData = json.load(file)\r\n",
        "\r\n",
        "modelPackage, modelName = utils.getNameAndPackage(module)\r\n",
        "modelType = utils.loadmodule(modelPackage, modelName)\r\n",
        "\r\n",
        "model = modelType(useGPU=True,\r\n",
        "                  storeAVG=True,\r\n",
        "                  **configData)\r\n",
        "\r\n",
        "\r\n",
        "model.load(pathModel)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('output_networks/default/default_train_config.json', 'output_networks/default/default_s4_i128000.pt', 'output_networks/default/default_s4_i128000_tmp_config.json')\n",
            "Average network found !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeeHmkDyB0jW"
      },
      "source": [
        "# Encoder Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0yrXiuw-uuw"
      },
      "source": [
        "def calc_alpha(e):\r\n",
        "  if e < 75:\r\n",
        "      return 0.1\r\n",
        "  return 1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "C45gpm_tSCAM"
      },
      "source": [
        "def train_encoder():\n",
        "    netG = model.avgG\n",
        "    netG.eval()\n",
        "    netD = model.netD\n",
        "    netD.eval()\n",
        "    for p in netD.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in netG.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    dataloader, validloader = get_dataloaders(train_data_path, valid_data_path, BATCH_SIZE)\n",
        "\n",
        "    netE = Encoder(DIM,NOISE_SIZE,0.3).to(device)\n",
        "    optimizer = optim.Adam(netE.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
        "    crit = nn.MSELoss()\n",
        "    rec_crit = nn.L1Loss()\n",
        "    \n",
        "    chkpts = os.listdir('encoder/')\n",
        "    if not chkpts: \n",
        "      print('starting from scratch...')\n",
        "      start_iter = 1\n",
        "    else:\n",
        "      print('loading checkpoint...')\n",
        "      chkpts = sorted(chkpts, reverse=True, key=lambda x : float(re.split('_|p',x)[1]))\n",
        "      checkpoint_fpathE = os.path.join('encoder/', chkpts[0])\n",
        "      print(checkpoint_fpathE)\n",
        "      checkpointEl = torch.load(checkpoint_fpathE)\n",
        "\n",
        "      netE.load_state_dict(checkpointEl['state_dict'])\n",
        "      optimizer.load_state_dict(checkpointEl['optimizer'])\n",
        "\n",
        "      start_iter = checkpointEl['epoch']\n",
        "\n",
        "    for e in range(start_iter, 300):\n",
        "        losses = []\n",
        "        netE.train()\n",
        "        options_alpha = 1\n",
        "        for (x, _) in dataloader:\n",
        "            x = x.to(device)\n",
        "            code = netE(x)\n",
        "            rec_image = netG(code)\n",
        "            code_rec = netE(rec_image)\n",
        "            f_x = netD.forward(x,getFeature=True)[1]\n",
        "            f_gx = netD.forward(rec_image.detach(),getFeature=True)[1]\n",
        "            loss = rec_crit(rec_image, x) + crit(code_rec, code) + options_alpha * crit(f_gx, f_x)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        print(e, np.mean(losses))\n",
        "        netE.eval()\n",
        "        rec_image = netG(netE(x))\n",
        "        d_input = torch.cat((x, rec_image), dim=0)\n",
        "        save_image(d_input, 'rec'+str(e)+'.jpg',normalize=True)\n",
        "        if e % 1 == 0:\n",
        "            checkpointE = {\n",
        "              'epoch': e + 1,\n",
        "              'state_dict': netE.state_dict(),\n",
        "              'optimizer': optimizer.state_dict()\n",
        "            }\n",
        "            torch.save(checkpointE, 'encoder/netE_%d.pth' % e)\n",
        "            evaluate(netG, netD, netE,options_alpha,validloader)\n",
        "            shutil.copy('encoder/netE_%d.pth' % e,'/content/drive/MyDrive/FYDP 2021/ANOGAN-Weights/PanoGAN/encoder/running/netE_%d.pth' % e)\n",
        "    torch.save(netE.state_dict(), 'wgangp/netE.pth')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YvmUl5VB4vS"
      },
      "source": [
        "# Evaluate Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZPh4qDKSKkR"
      },
      "source": [
        "def evaluate(netG, netD, netE,options_alpha, dataloader):\n",
        "    options_c = 0\n",
        "    netE.eval()\n",
        "    netD.eval()\n",
        "    netE.eval()\n",
        "\n",
        "    # crit = nn.MSELoss()\n",
        "    y_true, y_score = [], []\n",
        "    rec_scores, enc_scores, feat_scores = [], [], []\n",
        "    in_real, out_real, in_rec, out_rec = [], [], [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (x, label) in dataloader:\n",
        "            bs = x.size(0)\n",
        "            x = x.to(device)\n",
        "            code = netE(x)\n",
        "            rec_image = netG(code)\n",
        "            rec_code = netE(rec_image)\n",
        "\n",
        "            d_input = torch.cat((x, rec_image), dim=0)\n",
        "            idx = (label == options_c)\n",
        "            in_real.append(x[idx])\n",
        "            in_rec.append(rec_image[idx])\n",
        "            idx = (label != options_c)\n",
        "            out_real.append(x[idx])\n",
        "            out_rec.append(rec_image[idx])\n",
        "            # f_x = netD.forward(x,getFeature=True)[1]\n",
        "            # f_gx = netD.forward(rec_image,getFeature=True)[1]\n",
        "            \n",
        "            rec_diff = torch.abs((rec_image.view(bs, -1) - x.view(bs, -1)))\n",
        "            rec_score = rec_diff.mean(dim=1)\n",
        "            # rec_score = ssim_loss(rec_image, x,size_average=False)\n",
        "            rec_scores.append(rec_score.cpu().numpy())\n",
        "\n",
        "            enc_diff = torch.abs((rec_code-code))\n",
        "            #enc_score = enc_diff.mean(dim=1)\n",
        "            enc_scores.append(enc_diff.mean(dim=1).cpu().numpy())\n",
        "\n",
        "            # feat_diff = ((f_x - f_gx)**2)\n",
        "            # feat_score = feat_diff.mean(dim=1) \n",
        "            #feat_scores.append(feat_diff.mean(dim=1).cpu().numpy())\n",
        "\n",
        "            #plt.figure()\n",
        "            #plt.imshow(x[0,0].cpu())\n",
        "            #print(outlier_score.cpu().numpy())\n",
        "            # outlier_score = ssim_loss(rec_image, x, size_average=False)\n",
        "            y_true.append(label)\n",
        "            # y_score.append(outlier_score.cpu())\n",
        "\n",
        "    enc_scores = np.concatenate(enc_scores)\n",
        "    rec_scores = np.concatenate(rec_scores)\n",
        "    #feat_scores = np.concatenate(feat_scores)\n",
        "    rec_scores = (rec_scores - np.min(rec_scores)) / (np.max(rec_scores) - np.min(rec_scores))\n",
        "    #feat_score = (feat_scores - np.min(feat_scores)) / (np.max(feat_scores) - np.min(feat_scores))\n",
        "    enc_scores = (enc_scores - np.min(enc_scores)) / (np.max(enc_scores) - np.min(enc_scores))\n",
        "\n",
        "    y_score = rec_scores + enc_scores #+ feat_scores\n",
        "\n",
        "    in_real = torch.cat(in_real, dim=0)[:32]\n",
        "    in_rec = torch.cat(in_rec, dim=0)[:32]\n",
        "    out_real = torch.cat(out_real, dim=0)[:32]\n",
        "    out_rec = torch.cat(out_rec, dim=0)[:32]\n",
        "    save_image(torch.cat((in_real, in_rec), dim=0), 'healthy.jpg', normalize=True)\n",
        "    save_image(torch.cat((out_real, out_rec), dim=0),\n",
        "               'unhealthy.jpg', normalize=True)\n",
        "    # y_score = np.concatenate(y_score)\n",
        "    y_true = np.concatenate(y_true)\n",
        "    y_true[y_true != options_c] = -1\n",
        "    y_true[y_true == options_c] = 1\n",
        "    print('auc:', metrics.roc_auc_score(y_true, -y_score))\n",
        "    #plt.figure()\n",
        "    #plt.hist(y_score[y_true==1], 100, density=True, alpha=0.5, color='blue')\n",
        "    #plt.hist(y_score[y_true==-1], 100, density=True, alpha=0.5, color='red')\n",
        "    #plt.show()\n",
        "    return y_true, y_score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iut7K6lz3sVQ"
      },
      "source": [
        "# Test Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAHGTIZYcKQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da981f0-d570-4dbd-ff5d-333dd06ecb07"
      },
      "source": [
        "!pip install kornia"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kornia) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.7.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->kornia) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZfLRwNz_dIu"
      },
      "source": [
        "from kornia import gaussian_blur2d, median_blur"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcxAXuQyGYFT"
      },
      "source": [
        "def test(path):\r\n",
        "    options_alpha = 1\r\n",
        "    options_c = 0\r\n",
        "    netG = model.avgG\r\n",
        "    netG.eval()\r\n",
        "    netD = model.netD\r\n",
        "    netD.eval()\r\n",
        "    for p in netD.parameters():\r\n",
        "        p.requires_grad = False\r\n",
        "    for p in netG.parameters():\r\n",
        "        p.requires_grad = False\r\n",
        "\r\n",
        "    netE = Encoder(DIM,NOISE_SIZE).to(device)\r\n",
        "    optimizer = optim.Adam(netE.parameters(), lr=1e-4, betas=(0., 0.9),weight_decay=1e-5)\r\n",
        "    crit = nn.MSELoss()\r\n",
        "    rec_crit = nn.MSELoss()\r\n",
        "    \r\n",
        "    chkpts = os.listdir('encoder/')\r\n",
        "    if not chkpts: \r\n",
        "      print('starting from scratch...')\r\n",
        "      start_iter = 1\r\n",
        "    else:\r\n",
        "      print('loading checkpoint...')\r\n",
        "      chkpts = sorted(chkpts, reverse=True, key=lambda x : float(re.split('_|p',x)[1]))\r\n",
        "      checkpoint_fpathE = os.path.join('encoder/', chkpts[0])\r\n",
        "      print(checkpoint_fpathE)\r\n",
        "      checkpointEl = torch.load(checkpoint_fpathE)\r\n",
        "\r\n",
        "      netE.load_state_dict(checkpointEl['state_dict'])\r\n",
        "      optimizer.load_state_dict(checkpointEl['optimizer'])\r\n",
        "\r\n",
        "      start_iter = checkpointEl['epoch']\r\n",
        "    \r\n",
        "    netE.eval()\r\n",
        "    _, dataloader = get_dataloaders(train_data_path, path, BATCH_SIZE)\r\n",
        "    # crit = nn.MSELoss()\r\n",
        "    y_true, y_score = [], []\r\n",
        "    in_real, out_real, in_rec, out_rec = [], [], [], []\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        for (x, label) in dataloader:\r\n",
        "            bs = x.size(0)\r\n",
        "            x = x.to(device)\r\n",
        "            # denoise\r\n",
        "            x = median_blur(x,(5,5))\r\n",
        "            code = netE(x)\r\n",
        "            rec_image = netG(code)\r\n",
        "            rec_code = netE(rec_image)\r\n",
        "            # rec_image = median_blur(rec_image,(5,5))\r\n",
        "            d_input = torch.cat((x, rec_image), dim=0)\r\n",
        "            idx = (label == options_c)\r\n",
        "            in_real.append(x[idx])\r\n",
        "            in_rec.append(rec_image[idx])\r\n",
        "            idx = (label != options_c)\r\n",
        "            out_real.append(x[idx])\r\n",
        "            out_rec.append(rec_image[idx])\r\n",
        "            f_x = netD.forward(x,getFeature=True)[1]\r\n",
        "            f_gx = netD.forward(rec_image,getFeature=True)[1]\r\n",
        "\r\n",
        "            rec_diff = abs((rec_image.view(bs, -1) - x.view(bs, -1)))\r\n",
        "            rec_score = rec_diff.mean(dim=1) \r\n",
        "            rec_score = rec_score + ssim_loss(rec_image, x, size_average=False)\r\n",
        "            feat_diff = ((f_x - f_gx)**2)\r\n",
        "            feat_score = feat_diff.mean(dim=1) \r\n",
        "            enc_score =((rec_code - code)**2)\r\n",
        "            enc_score = enc_score.mean(dim=1)\r\n",
        "            outlier_score = rec_score + options_alpha * feat_score\r\n",
        "            # outlier_score = rec_score + enc_score\r\n",
        "            #plt.figure()\r\n",
        "            #plt.imshow(x[0,0].cpu())\r\n",
        "            #print(outlier_score.cpu().numpy())\r\n",
        "            # outlier_score = ssim_loss(rec_image, x, size_average=False)\r\n",
        "            y_true.append(label)\r\n",
        "            y_score.append(outlier_score.cpu())\r\n",
        "    in_real = torch.cat(in_real, dim=0)[:32]\r\n",
        "    in_rec = torch.cat(in_rec, dim=0)[:32]\r\n",
        "    out_real = torch.cat(out_real, dim=0)[:32]\r\n",
        "    out_rec = torch.cat(out_rec, dim=0)[:32]\r\n",
        "    save_image(torch.cat((in_real, in_rec), dim=0), 'test-healthy.jpg', normalize=True)\r\n",
        "    save_image(torch.cat((out_real, out_rec), dim=0),\r\n",
        "               'test-unhealthy.jpg', normalize=True)\r\n",
        "    y_score = np.concatenate(y_score)\r\n",
        "    y_true = np.concatenate(y_true)\r\n",
        "    y_true[y_true != options_c] = -1\r\n",
        "    y_true[y_true == options_c] = 1\r\n",
        "    print('auc:', metrics.roc_auc_score(y_true, -y_score))\r\n",
        "    plt.figure()\r\n",
        "    plt.hist(y_score[y_true==1], 100, density=True, alpha=0.5, color='blue')\r\n",
        "    plt.hist(y_score[y_true==-1], 100, density=True, alpha=0.5, color='red')\r\n",
        "    plt.show()\r\n",
        "    return y_true, y_score"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSFXN64jk8Oo"
      },
      "source": [
        "def test(path):\r\n",
        "    options_c = 0\r\n",
        "    netG = model.avgG\r\n",
        "    netG.eval()\r\n",
        "    netD = model.netD\r\n",
        "    netD.eval()\r\n",
        "    for p in netD.parameters():\r\n",
        "        p.requires_grad = False\r\n",
        "    for p in netG.parameters():\r\n",
        "        p.requires_grad = False\r\n",
        "\r\n",
        "    netE = Encoder(DIM,NOISE_SIZE).to(device)\r\n",
        "    optimizer = optim.Adam(netE.parameters(), lr=1e-4, betas=(0., 0.9),weight_decay=1e-5)\r\n",
        "    crit = nn.MSELoss()\r\n",
        "    rec_crit = nn.MSELoss()\r\n",
        "    \r\n",
        "    chkpts = os.listdir('encoder/')\r\n",
        "    if not chkpts: \r\n",
        "      print('starting from scratch...')\r\n",
        "      start_iter = 1\r\n",
        "    else:\r\n",
        "      print('loading checkpoint...')\r\n",
        "      chkpts = sorted(chkpts, reverse=True, key=lambda x : float(re.split('_|p',x)[1]))\r\n",
        "      checkpoint_fpathE = os.path.join('encoder/', chkpts[0])\r\n",
        "      print(checkpoint_fpathE)\r\n",
        "      checkpointEl = torch.load(checkpoint_fpathE)\r\n",
        "\r\n",
        "      netE.load_state_dict(checkpointEl['state_dict'])\r\n",
        "      optimizer.load_state_dict(checkpointEl['optimizer'])\r\n",
        "\r\n",
        "      start_iter = checkpointEl['epoch']\r\n",
        "    \r\n",
        "    netE.eval()\r\n",
        "    for p in netE.parameters():\r\n",
        "        p.requires_grad = False\r\n",
        "\r\n",
        "    dataloader, _ = get_dataloaders(train_data_path, path, BATCH_SIZE)\r\n",
        "    # crit = nn.MSELoss()\r\n",
        "    y_true, y_score = [], []\r\n",
        "    in_real, out_real, in_rec, out_rec = [], [], [], []\r\n",
        "    rec_scores, enc_scores, feat_scores = [], [], []\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        for (x, label) in dataloader:\r\n",
        "            bs = x.size(0)\r\n",
        "            x = x.to(device)\r\n",
        "            # denoise\r\n",
        "            # x = median_blur(x,(5,5))\r\n",
        "            code = netE(x)\r\n",
        "            rec_image = netG(code)\r\n",
        "            rec_code = netE(rec_image)\r\n",
        "            # rec_image = median_blur(rec_image,(5,5))\r\n",
        "            d_input = torch.cat((x, rec_image), dim=0)\r\n",
        "            idx = (label == options_c)\r\n",
        "            in_real.append(x[idx])\r\n",
        "            in_rec.append(rec_image[idx])\r\n",
        "            idx = (label != options_c)\r\n",
        "            out_real.append(x[idx])\r\n",
        "            out_rec.append(rec_image[idx])\r\n",
        "            f_x = netD.forward(x,getFeature=True)[1]\r\n",
        "            f_gx = netD.forward(rec_image,getFeature=True)[1]\r\n",
        "            rec_diff = torch.abs((rec_image.view(bs, -1) - x.view(bs, -1)))\r\n",
        "            rec_score = rec_diff.mean(dim=1) \r\n",
        "            rec_scores.append(rec_score.cpu().numpy())\r\n",
        "            \r\n",
        "            feat_diff = torch.pow((f_x - f_gx),2)\r\n",
        "            feat_score = feat_diff.mean(dim=1) \r\n",
        "            feat_scores.append(feat_diff.mean(dim=1).cpu().numpy())\r\n",
        "\r\n",
        "            enc_diff = torch.abs((rec_code-code))\r\n",
        "            enc_score = enc_diff.mean(dim=1)\r\n",
        "            enc_scores.append(enc_score.cpu().numpy())\r\n",
        "\r\n",
        "            # outlier_score = rec_score + options_alpha * feat_score + enc_score\r\n",
        "            y_true.append(label)\r\n",
        "            # y_score.append(outlier_score.cpu())\r\n",
        "    \r\n",
        "    # normalize\r\n",
        "    enc_scores = np.concatenate(enc_scores)\r\n",
        "    rec_scores = np.concatenate(rec_scores)\r\n",
        "    feat_scores = np.concatenate(feat_scores)\r\n",
        "    rec_scores = (rec_scores - np.min(rec_scores)) / (np.max(rec_scores) - np.min(rec_scores))\r\n",
        "    feat_scores = (feat_scores - np.min(feat_scores)) / (np.max(feat_scores) - np.min(feat_scores))\r\n",
        "    enc_scores = (enc_scores - np.min(enc_scores)) / (np.max(enc_scores) - np.min(enc_scores))\r\n",
        "\r\n",
        "    y_score = rec_scores + enc_scores + feat_scores\r\n",
        "\r\n",
        "    in_real = torch.cat(in_real, dim=0)[:64]\r\n",
        "    in_rec = torch.cat(in_rec, dim=0)[:64]\r\n",
        "    out_real = torch.cat(out_real, dim=0)[:64]\r\n",
        "    out_rec = torch.cat(out_rec, dim=0)[:64]\r\n",
        "    save_image(torch.cat((in_real, in_rec), dim=0), 'test-healthy.jpg', normalize=True)\r\n",
        "    save_image(torch.cat((out_real, out_rec), dim=0),\r\n",
        "               'test-unhealthy.jpg', normalize=True)\r\n",
        "    \r\n",
        "    # y_score = np.concatenate(y_score)\r\n",
        "    y_true = np.concatenate(y_true)\r\n",
        "    y_true[y_true != options_c] = -1\r\n",
        "    y_true[y_true == options_c] = 1\r\n",
        "    print('auc:', metrics.roc_auc_score(y_true, -y_score))\r\n",
        "    plt.figure()\r\n",
        "    plt.hist(y_score[y_true==1], 100, density=True, alpha=0.5, color='blue')\r\n",
        "    plt.hist(y_score[y_true==-1], 100, density=True, alpha=0.5, color='red')\r\n",
        "    plt.show()\r\n",
        "    return y_true, y_score"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PizW8E4VB66l"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGqUu9xyVyCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c77d4fb-dcee-4e37-eeae-bbed057b7f75"
      },
      "source": [
        "options_eval = False\n",
        "options_stage = 2\n",
        "if not options_eval:\n",
        "    if options_stage == 1:\n",
        "        wgan_training()\n",
        "    elif options_stage == 2:\n",
        "        train_encoder()\n",
        "else:\n",
        "    y_true, y_score = evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting from scratch...\n",
            "1 0.3935696820427022\n",
            "auc: 0.703727906731168\n",
            "2 0.32655378122549594\n",
            "auc: 0.7069555249815205\n",
            "3 0.31356880630603967\n",
            "auc: 0.7223483103594456\n",
            "4 0.30510305195615695\n",
            "auc: 0.7232374740405525\n",
            "5 0.297950849179549\n",
            "auc: 0.7214224170254184\n",
            "6 0.2925058993734891\n",
            "auc: 0.7051634239994613\n",
            "7 0.28678671498302954\n",
            "auc: 0.6967814111226571\n",
            "8 0.28179782684252447\n",
            "auc: 0.704138054522109\n",
            "9 0.27816694964120875\n",
            "auc: 0.6923233494994819\n",
            "10 0.27562858502483284\n",
            "auc: 0.6928528686624132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpMM_P_Hkm8"
      },
      "source": [
        "!rm -r encoder/\r\n",
        "!mkdir encoder/\r\n",
        "\r\n",
        "for img in os.listdir(\"./\"):\r\n",
        "  if img[-3:] == \"jpg\":\r\n",
        "    os.remove(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pntPoBU0HNa"
      },
      "source": [
        "test(valid_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}