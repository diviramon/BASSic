{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PanoGAN_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diviramon/BASSic/blob/master/PanoGAN_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7zy0qm4qrci",
        "outputId": "8762d166-2454-4f68-acbb-5157656bd5c2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar  4 20:16:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi37gsnXq6dh",
        "outputId": "68fd99f5-a17b-4c6f-8551-934aeda7d220"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qqc8FvuMVBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6c8cf9-9724-40d0-838c-032ea3e88410"
      },
      "source": [
        "!pip install pydicom\n",
        "!pip install pytorch-msssim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/15/df16546bc59bfca390cf072d473fb2c8acd4231636f64356593a63137e55/pydicom-2.1.2-py3-none-any.whl (1.9MB)\n",
            "\r\u001b[K     |▏                               | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 23.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 25.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 19.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 14.7MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 13.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 12.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 14.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92kB 14.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102kB 13.5MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 13.5MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▉                             | 163kB 13.5MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 184kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215kB 13.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225kB 13.5MB/s eta 0:00:01\r\u001b[K     |████                            | 235kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 256kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 276kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 296kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 307kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 327kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 348kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 358kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 368kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 378kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 399kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 409kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 419kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 430kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 440kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 450kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 460kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 471kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 491kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 501kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 512kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 522kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 542kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 552kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 563kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 573kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 583kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 593kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 604kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 614kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 624kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 634kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 645kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 655kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 665kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 675kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 686kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 696kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 716kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 727kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 737kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 747kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 757kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 768kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 778kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 788kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 798kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 808kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 819kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 829kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 839kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 849kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 860kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 870kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 880kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 890kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 901kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 911kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 921kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 931kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 942kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 952kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 962kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 972kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 983kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 993kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.0MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.7MB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.8MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9MB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 13.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.1.2\n",
            "Collecting pytorch-msssim\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/d3/3cb0f397232cf79e1762323c3a8862e39ad53eca0bb5f6be9ccc8e7c070e/pytorch_msssim-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-msssim) (1.7.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (1.19.5)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lW9VN4GBSr3"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SgV287Q7i4"
      },
      "source": [
        "DIM = 64\n",
        "OUTPUT_DIM = DIM*DIM*1\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import cv2\n",
        "import re\n",
        "import random\n",
        "from skimage.io import imread \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.autograd import grad\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import random_split, ConcatDataset\n",
        "\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, average_precision_score, f1_score\n",
        "from scipy.optimize import brentq\n",
        "from scipy.interpolate import interp1d\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pydicom as dcm\n",
        "from skimage import io, exposure\n",
        "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import autograd\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import sampler\n",
        "from argparse import ArgumentParser\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-uHk07CBVK5"
      },
      "source": [
        "# Make Folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ1w65QGS-dm"
      },
      "source": [
        "!rm -r sample_data/\n",
        "!mkdir data\n",
        "!mkdir data/train\n",
        "!mkdir data/train/healthy\n",
        "!mkdir data/valid\n",
        "!mkdir data/valid/healthy\n",
        "!mkdir data/valid/nodule\n",
        "!mkdir data/test/\n",
        "!mkdir data/test/healthy\n",
        "!mkdir data/test/nodule\n",
        "!mkdir data/patients/\n",
        "!mkdir output/\n",
        "!mkdir output/patients/\n",
        "\n",
        "!mkdir encoder"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UuoCc3eBXQa"
      },
      "source": [
        "# Read Image Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6ev8OpNLXKr"
      },
      "source": [
        "def read_indiana(file_name, cxr_path, mask_path):\n",
        "  \n",
        "  dcm_filename = file_name[3:-4] + '.dcm'\n",
        "\n",
        "  # Pre-process mask\n",
        "  mask = cv2.imread(os.path.join(mask_path, file_name))\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "  mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
        "  mask = (mask > 127) * 255\n",
        "\n",
        "  # Read in DICOM \n",
        "  ds = dcm.dcmread(os.path.join(cxr_path, dcm_filename))\n",
        "  cxr = ds.pixel_array\n",
        "  #print(ds.PhotometricInterpretation)\n",
        "  #cxr = dcm.pixel_data_handlers.util.apply_voi_lut(cxr, ds, index=0)\n",
        "  cxr = cv2.resize(cxr, (1024, 1024))\n",
        "  if ds.PhotometricInterpretation == 'MONOCHROME1':\n",
        "    cxr = 1.0 - cxr * 1./cxr.max()\n",
        "  else:\n",
        "    cxr = cxr * 1. / cxr.max()\n",
        "  cxr = exposure.equalize_adapthist(cxr,kernel_size=128)\n",
        "  normalizedImg = np.zeros((1024, 1024))\n",
        "  cxr = cv2.normalize(cxr,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "  return mask, cxr"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODytx0lWLXxp"
      },
      "source": [
        "def read_nih(file_name, cxr_path, mask_path):\n",
        "  \n",
        "  # Pre-process mask\n",
        "  mask = cv2.imread(os.path.join(mask_path, file_name))\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "  mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
        "  mask = (mask > 127) * 255\n",
        "  \n",
        "  # Read in PNG\n",
        "  cxr = cv2.imread(os.path.join(cxr_path, file_name))\n",
        "  cxr = cv2.cvtColor(cxr, cv2.COLOR_BGR2GRAY)\n",
        "  cxr = cv2.resize(cxr, (1024, 1024)) \n",
        "  cxr = cxr * 1./cxr.max()\n",
        "  cxr = exposure.equalize_adapthist(cxr,kernel_size=128)\n",
        "  normalizedImg = np.zeros((1024, 1024))\n",
        "  cxr = cv2.normalize(cxr,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "  return mask, cxr"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD5nusdNLaW8"
      },
      "source": [
        "def read_jsrt(file_name, cxr_path, mask_path):\n",
        "\n",
        "  # Pre-process mask\n",
        "  mask = cv2.imread(os.path.join(mask_path, file_name))\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "  mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
        "  mask = (mask > 127) * 255\n",
        "\n",
        "  # Read in IMG\n",
        "  # fname = file_name[:-4] + '.IMG'\n",
        "  # cxr = 1.0 - np.fromfile(os.path.join(cxr_path, fname), dtype='>u2').reshape((2048, 2048)) * 1. / 4095\n",
        "  cxr = cv2.imread(os.path.join(cxr_path, file_name))\n",
        "  cxr = cv2.cvtColor(cxr, cv2.COLOR_BGR2GRAY)\n",
        "  cxr = cv2.resize(cxr, (1024, 1024)) \n",
        "  cxr = cxr * 1./cxr.max()\n",
        "  cxr = exposure.equalize_adapthist(cxr,kernel_size=128)\n",
        "  normalizedImg = np.zeros((1024, 1024))\n",
        "  cxr = cv2.normalize(cxr,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "  return mask, cxr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNXphgg8Lb3O"
      },
      "source": [
        "def crop_patches(image, mask, total_patches, box, image_name, dataset, svpath):\n",
        "  if dataset == 'indiana':\n",
        "    patch_extractor = ExtractPatches(image_name, image, mask, box, DIM, DIM//2, dataset, svpath)\n",
        "  else:\n",
        "    patch_extractor = ExtractPatches(image_name, image, mask, box, DIM, DIM//4, dataset, svpath)\n",
        "  \n",
        "  lung_area = np.count_nonzero(mask)\n",
        "  patches = patch_extractor.extract_all_patches()\n",
        "  total_patches = total_patches + patches\n",
        "\n",
        "  return total_patches"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLQTelfzLdvf"
      },
      "source": [
        "class ExtractPatches:\n",
        "    def __init__(self, image_name, image, mask, bbox, patchSize, stride, dataset, out_path):\n",
        "        self.image = image\n",
        "        self.out_path = out_path\n",
        "        self.dataset = dataset\n",
        "        self.bbox = bbox\n",
        "        self.annotated = np.copy(image) \n",
        "        self.reconstructed = np.empty(image.shape)\n",
        "        self.reconstructed[:] = np.nan\n",
        "        self.image_name = image_name\n",
        "        self.patchSize = patchSize\n",
        "        self.stride = stride\n",
        "        self.mask = mask\n",
        "\n",
        "    def draw_single_patches(self, coords, patch):\n",
        "      y1 = coords[0] * self.stride\n",
        "      x1 = coords[1] * self.stride\n",
        "      y2 = coords[0] * self.stride + self.patchSize\n",
        "      x2 = coords[1] * self.stride + self.patchSize\n",
        "      self.annotated = cv2.rectangle(self.annotated,(x1,y1), (x2,y2), (0, 0, 255))\n",
        "      self.reconstructed[y1:y2, x1:x2] = patch\n",
        "    \n",
        "    def extract_single_patches(self, patch):\n",
        "        croppedPatches = self.image[(patch[0] * self.stride):(patch[0] * self.stride + self.patchSize), \n",
        "                               (patch[1] * self.stride):(patch[1] * self.stride + self.patchSize)]\n",
        "        return croppedPatches\n",
        "\n",
        "    def no_of_patches(self):\n",
        "        yNoOfPatches, xNoOfPatches = (int((self.image.shape[1] - self.patchSize) / self.stride + 1),\n",
        "                                      int((self.image.shape[0] - self.patchSize) / self.stride + 1))\n",
        "        return xNoOfPatches, yNoOfPatches\n",
        "\n",
        "    def extract_all_patches(self):\n",
        "        xNoOfPatches, yNoOfPatches = self.no_of_patches()\n",
        "        closest = None\n",
        "        closest_dist = 10000\n",
        "\n",
        "        allPatches = list()\n",
        "        for y in range(yNoOfPatches):\n",
        "            for x in range(xNoOfPatches):\n",
        "              patch = self.extract_single_patches((x,y))\n",
        "                            \n",
        "              y1 = x * self.stride\n",
        "              x1 = y * self.stride\n",
        "              y2 = x * self.stride + self.patchSize\n",
        "              x2 = y * self.stride + self.patchSize\n",
        "              mask_cover = np.sum(self.mask[y1:y2, x1:x2])\n",
        "              if x1 > 0 and x2 < 1024 and y1 > 0 and y2 < 1024:\n",
        "                if patch.shape[0] == self.patchSize and patch.shape[1] and mask_cover/(255*self.patchSize*self.patchSize) > 0.75:\n",
        "                  if self.dataset == 'jsrt-nodule':\n",
        "                      cx = self.bbox[0]\n",
        "                      cy = self.bbox[1]\n",
        "                      if (x1 < cx) and (x2 > cx) and (y1 < cy) and (y2 > cy):\n",
        "                          bbox_cx = (x1+x2)//2\n",
        "                          bbox_cy = (y1+y2)//2\n",
        "                          if ((bbox_cx-cx)**2 + (bbox_cy-cy)**2) < closest_dist:\n",
        "                              closest_dist = (bbox_cx-cx)**2 + (bbox_cy-cy)**2\n",
        "                              closest = patch\n",
        "                              closest_x = x\n",
        "                              closest_y = y\n",
        "                          self.draw_single_patches((x,y), patch)\n",
        "                  elif self.dataset == 'nih-nodule':\n",
        "                      cx = (self.bbox[0] + self.bbox[2])//2\n",
        "                      cy = (self.bbox[1] + self.bbox[3])//2\n",
        "                      if (x1 < cx) and (x2 > cx) and (y1 < cy) and (y2 > cy):\n",
        "                          bbox_cx = (x1+x2)//2\n",
        "                          bbox_cy = (y1+y2)//2\n",
        "                          if ((bbox_cx-cx)**2 + (bbox_cy-cy)**2) < closest_dist:\n",
        "                              closest_dist = (bbox_cx-cx)**2 + (bbox_cy-cy)**2\n",
        "                              closest = patch\n",
        "                              closest_x = x\n",
        "                              closest_y = y\n",
        "                          self.draw_single_patches((x,y), patch)\n",
        "                  else:\n",
        "                      allPatches.append(patch)\n",
        "                      cv2.imwrite(self.out_path + str(x) + '_' + str(y) + '_' + self.image_name, patch)\n",
        "                      # plt.imsave(self.out_path + str(x) + '_' + str(y) + '_' + self.image_name, patch, cmap='gray')\n",
        "                      self.draw_single_patches((x,y), patch)\n",
        "        \n",
        "        if closest is not None:\n",
        "            allPatches.append(closest)\n",
        "            cv2.imwrite(self.out_path + str(closest_x) + '_' + str(closest_y) + '_' + self.image_name, closest)\n",
        "            # plt.imsave(self.out_path + str(closest_x) + '_' + str(closest_y) + '_' + self.image_name, closest, cmap='gray')\n",
        "\n",
        "        #cv2_imshow(self.annotated)\n",
        "\n",
        "        return allPatches"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysRjrn3yBc15"
      },
      "source": [
        "# Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tefDiouvLflW"
      },
      "source": [
        "jsrt_mask_path = '/content/drive/MyDrive/FYDP 2021/JSRT Data/JSRT Masks'\n",
        "jsrt_cxr_path = '/content/drive/MyDrive/FYDP 2021/JSRT Data/JSRT Images'\n",
        "\n",
        "nih_healthy_mask_path = '/content/drive/MyDrive/FYDP 2021/NIH-Data/Healthy_masks'\n",
        "nih_healthy_cxr_path = '/content/drive/MyDrive/FYDP 2021/NIH-Data/Healthy_raw'\n",
        "\n",
        "nih_nodule_mask_path = '/content/drive/MyDrive/FYDP 2021/NIH-Data/Nodule_masks'\n",
        "nih_nodule_cxr_path = '/content/drive/MyDrive/FYDP 2021/NIH-Data/Nodule_raw'\n",
        "\n",
        "indiana_mask_path = '/content/drive/My Drive/FYDP 2021/Indiana University Database/Additional Masks'\n",
        "indiana_cxr_path = '/content/drive/My Drive/FYDP 2021/Indiana University Database/DICOM Frontal'\n",
        "\n",
        "nih_healthy_img_list = os.listdir(nih_healthy_mask_path)\n",
        "indiana_img_list = os.listdir(indiana_mask_path)\n",
        "\n",
        "nih_info = pd.read_csv('/content/drive/MyDrive/FYDP 2021/NIH-Data/BBox_List_2017.csv')\n",
        "nih_info = nih_info[nih_info['Finding Label']=='Nodule']\n",
        "nih_nodule_list = nih_info['Image Index'].values\n",
        "\n",
        "jsrt_info = pd.read_csv('/content/drive/MyDrive/FYDP 2021/JSRT Data/jsrt_metadata (1).csv')\n",
        "jsrt_healthy_info = jsrt_info[jsrt_info['state']=='non-nodule']\n",
        "jsrt_healthy_list = jsrt_healthy_info['study_id'].values\n",
        "jsrt_nodule_info = jsrt_info[jsrt_info['state']!='non-nodule']\n",
        "jsrt_nodule_list = jsrt_nodule_info['study_id'].values\n",
        "\n",
        "batchsize = 64\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG0CQWQ2BeoR"
      },
      "source": [
        "# Load Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrd3ASF0Bhs8"
      },
      "source": [
        "### Indiana"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6S410tvLv3t",
        "outputId": "d99cb036-8636-405c-9dba-b9bcbc46b9f8"
      },
      "source": [
        "total_patches = []\n",
        "for j in range(len(indiana_img_list)):\n",
        "    image_name = indiana_img_list[j]\n",
        "    #print(image_name)\n",
        "    box = []\n",
        "    mask, cxr = read_indiana(image_name, indiana_cxr_path, indiana_mask_path)\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'indiana', 'data/train/healthy/')\n",
        "len(total_patches)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RUXmHDRBjgQ"
      },
      "source": [
        "### NIH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTI57h0VLxPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87aae1c0-db88-4d40-8dc3-fb7d5b05fa9a"
      },
      "source": [
        "total_patches = []\n",
        "for j in range(len(nih_healthy_img_list)):\n",
        "    image_name = nih_healthy_img_list[j]\n",
        "    #print(image_name)\n",
        "    box = []\n",
        "    mask, cxr = read_nih(image_name, nih_healthy_cxr_path, nih_healthy_mask_path)\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'nih-healthy', 'data/valid/healthy/')\n",
        "len(total_patches)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKWa5njFLy7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9c5b2c-dd5d-43fe-9f1b-e4c1517a1739"
      },
      "source": [
        "total_patches = []\n",
        "for j in range(len(nih_nodule_list)):\n",
        "    image_name = nih_nodule_list[j]\n",
        "    #print(image_name)\n",
        "    bx = nih_info['Bbox [x'].values[j]\n",
        "    by = nih_info['y'].values[j]\n",
        "    bh = nih_info['h]'].values[j]\n",
        "    bw = nih_info['w'].values[j]\n",
        "    box = [bx,by, bx+bw, by+bh]\n",
        "    mask, cxr = read_nih(image_name, nih_nodule_cxr_path, nih_nodule_mask_path)\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'nih-nodule', 'data/valid/nodule/')\n",
        "len(total_patches)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPcE_L6gL01i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0b246a-7a2b-4087-bd76-4ac31ee20241"
      },
      "source": [
        "files = os.listdir(path='data/valid/healthy')\n",
        "nfiles = len(files) + len(os.listdir(\"data/valid/nodule\"))\n",
        "if nfiles % batchsize != 0:\n",
        "  del_files = random.sample(files,nfiles%batchsize)\n",
        "  for dfile in del_files:\n",
        "    os.remove(os.path.join(\"data/valid/healthy/\", dfile))\n",
        "  print(\"Files removed: \", len(del_files))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files removed:  59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soT_7J9A2gm5"
      },
      "source": [
        "## JSRT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QLU_-pL2jOo"
      },
      "source": [
        "total_patches = []\r\n",
        "for j in range(len(jsrt_nodule_list)):\r\n",
        "    image_name = jsrt_nodule_list[j]\r\n",
        "    #print(image_name)\r\n",
        "    bx = jsrt_nodule_info['x'].values[j]/2\r\n",
        "    by = jsrt_nodule_info['y'].values[j]/2\r\n",
        "    box = [bx,by]\r\n",
        "    mask, cxr = read_jsrt(image_name, jsrt_cxr_path, jsrt_mask_path)\r\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'jsrt-nodule', 'data/test/nodule/')\r\n",
        "len(total_patches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go-B3imW2o6q"
      },
      "source": [
        "total_patches = []\r\n",
        "jsrt_healthy_list = list(jsrt_healthy_list)\r\n",
        "\r\n",
        "for j in range(len(jsrt_healthy_list)):\r\n",
        "    image_name = jsrt_healthy_list[j]\r\n",
        "    print(image_name)\r\n",
        "    box = []\r\n",
        "    mask, cxr = read_jsrt(image_name, jsrt_cxr_path, jsrt_mask_path)\r\n",
        "    total_patches = crop_patches(cxr, mask, total_patches, box, image_name, 'jsrt-healthy', 'data/test/healthy/')\r\n",
        "len(total_patches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM4yo_qd3Z4o"
      },
      "source": [
        "files = os.listdir(path='data/test/healthy')\r\n",
        "nfiles = len(files) + len(os.listdir(\"data/test/nodule\"))\r\n",
        "if nfiles % batchsize != 0:\r\n",
        "  del_files = random.sample(files,nfiles%batchsize)\r\n",
        "  for dfile in del_files:\r\n",
        "    os.remove(os.path.join(\"data/test/healthy/\", dfile))\r\n",
        "  print(\"Files removed: \", len(del_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS2lz0v7BmJd"
      },
      "source": [
        "# NN Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikmAgOieRDpv"
      },
      "source": [
        "class MyConvo2d(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init=True,  stride=1, bias=True):\n",
        "        super(MyConvo2d, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.padding = int((kernel_size - 1)/2)\n",
        "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size,\n",
        "                              stride=1, padding=self.padding, bias=bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        return output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GMjSW7YRG1W"
      },
      "source": [
        "class ConvMeanPool(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init=True):\n",
        "        super(ConvMeanPool, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim,\n",
        "                              kernel_size, he_init=self.he_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        output = (output[:, :, ::2, ::2] + output[:, :, 1::2, ::2] +\n",
        "                  output[:, :, ::2, 1::2] + output[:, :, 1::2, 1::2]) / 4\n",
        "        return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1kH5oKKRJYn"
      },
      "source": [
        "class MeanPoolConv(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init=True):\n",
        "        super(MeanPoolConv, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim,\n",
        "                              kernel_size, he_init=self.he_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = (output[:, :, ::2, ::2] + output[:, :, 1::2, ::2] +\n",
        "                  output[:, :, ::2, 1::2] + output[:, :, 1::2, 1::2]) / 4\n",
        "        output = self.conv(output)\n",
        "        return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28YhPArqRMs5"
      },
      "source": [
        "class DepthToSpace(nn.Module):\n",
        "    def __init__(self, block_size):\n",
        "        super(DepthToSpace, self).__init__()\n",
        "        self.block_size = block_size\n",
        "        self.block_size_sq = block_size*block_size\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input.permute(0, 2, 3, 1)\n",
        "        (batch_size, input_height, input_width, input_depth) = output.size()\n",
        "        output_depth = int(input_depth / self.block_size_sq)\n",
        "        output_width = int(input_width * self.block_size)\n",
        "        output_height = int(input_height * self.block_size)\n",
        "        t_1 = output.reshape(batch_size, input_height,\n",
        "                             input_width, self.block_size_sq, output_depth)\n",
        "        spl = t_1.split(self.block_size, 3)\n",
        "        stacks = [t_t.reshape(batch_size, input_height,\n",
        "                              output_width, output_depth) for t_t in spl]\n",
        "        output = torch.stack(stacks, 0).transpose(0, 1).permute(0, 2, 1, 3, 4).reshape(\n",
        "            batch_size, output_height, output_width, output_depth)\n",
        "        output = output.permute(0, 3, 1, 2)\n",
        "        return output"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BmPaG7qROvE"
      },
      "source": [
        "class UpSampleConv(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init=True, bias=True):\n",
        "        super(UpSampleConv, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim,\n",
        "                              kernel_size, he_init=self.he_init, bias=bias)\n",
        "        self.depth_to_space = DepthToSpace(2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = torch.cat((output, output, output, output), 1)\n",
        "        output = self.depth_to_space(output)\n",
        "        output = self.conv(output)\n",
        "        return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rQAeQLGRQgy"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, resample=None, hw=DIM):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.resample = resample\n",
        "        self.bn1 = None\n",
        "        self.bn2 = None\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "        if resample == 'down':\n",
        "            self.bn1 = nn.LayerNorm([input_dim, hw, hw])\n",
        "            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n",
        "        elif resample == 'up':\n",
        "            self.bn1 = nn.BatchNorm2d(input_dim)\n",
        "            self.bn2 = nn.BatchNorm2d(output_dim)\n",
        "        elif resample == 'custom':\n",
        "            self.bn1 = nn.InstanceNorm2d(input_dim)\n",
        "            self.bn2 = nn.InstanceNorm2d(output_dim)\n",
        "        else:\n",
        "            raise Exception('invalid resample value')\n",
        "\n",
        "        if resample == 'down':\n",
        "            self.conv_shortcut = MeanPoolConv(\n",
        "                input_dim, output_dim, kernel_size=1, he_init=False)\n",
        "            self.conv_1 = MyConvo2d(\n",
        "                input_dim, input_dim, kernel_size=kernel_size, bias=False)\n",
        "            self.conv_2 = ConvMeanPool(\n",
        "                input_dim, output_dim, kernel_size=kernel_size)\n",
        "        elif resample == 'up':\n",
        "            self.conv_shortcut = UpSampleConv(\n",
        "                input_dim, output_dim, kernel_size=1, he_init=False)\n",
        "            self.conv_1 = UpSampleConv(\n",
        "                input_dim, output_dim, kernel_size=kernel_size, bias=False)\n",
        "            self.conv_2 = MyConvo2d(\n",
        "                output_dim, output_dim, kernel_size=kernel_size)\n",
        "        elif resample == \"custom\":\n",
        "            self.conv_shortcut = MeanPoolConv(\n",
        "                input_dim, output_dim, kernel_size=1, he_init=False)\n",
        "            self.conv_1 = MyConvo2d(\n",
        "                input_dim, input_dim, kernel_size=kernel_size, bias=False)\n",
        "            self.conv_2 = ConvMeanPool(\n",
        "                input_dim, output_dim, kernel_size=kernel_size)\n",
        "        else:\n",
        "            raise Exception('invalid resample value')\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.input_dim == self.output_dim and self.resample == None:\n",
        "            shortcut = input\n",
        "        else:\n",
        "            shortcut = self.conv_shortcut(input)\n",
        "\n",
        "        output = input\n",
        "        output = self.bn1(output)\n",
        "        output = self.relu1(output)\n",
        "        output = self.conv_1(output)\n",
        "        output = self.bn2(output)\n",
        "        output = self.relu2(output)\n",
        "        output = self.conv_2(output)\n",
        "\n",
        "        return shortcut + output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT-34TZ7RTq7"
      },
      "source": [
        "class ReLULayer(nn.Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(ReLULayer, self).__init__()\n",
        "        self.n_in = n_in\n",
        "        self.n_out = n_out\n",
        "        self.linear = nn.Linear(n_in, n_out)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.linear(input)\n",
        "        output = self.relu(output)\n",
        "        return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqrKQAfCRWQt"
      },
      "source": [
        "class FCGenerator(nn.Module):\n",
        "    def __init__(self, FC_DIM=512):\n",
        "        super(FCGenerator, self).__init__()\n",
        "        self.relulayer1 = ReLULayer(128, FC_DIM)\n",
        "        self.relulayer2 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.relulayer3 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.relulayer4 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.linear = nn.Linear(FC_DIM, OUTPUT_DIM)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.relulayer1(input)\n",
        "        output = self.relulayer2(output)\n",
        "        output = self.relulayer3(output)\n",
        "        output = self.relulayer4(output)\n",
        "        output = self.linear(output)\n",
        "        output = self.tanh(output)\n",
        "        return output"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F4VC2MgReYU"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dim, output_dim, drop_rate=0.0):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(drop_rate)\n",
        "        self.conv_in = nn.Conv2d(1, dim, 3, 1, padding=1)\n",
        "        self.res1 = ResidualBlock(dim, dim*2, 3, 'down', DIM)\n",
        "        self.res2 = ResidualBlock(dim*2, dim*4, 3, 'down', int(DIM/2))\n",
        "        self.res3 = ResidualBlock(dim*4, dim*8, 3, 'down', int(DIM/4))\n",
        "        self.res4 = ResidualBlock(dim*8, dim*8, 3, 'down', int(DIM/8))\n",
        "        self.fc = nn.Linear(4*4*8*dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.dropout(x)\n",
        "        x = self.conv_in(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        x = self.res3(x)\n",
        "        x = self.res4(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(self.fc(x))\n",
        "        return torch.tanh(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EboMTn_QwP0"
      },
      "source": [
        "from pytorch_msssim import ssim\r\n",
        "\r\n",
        "def ssim_loss(input,target,size_average=True):\r\n",
        "    input = (input + 1) / 2\r\n",
        "    target = (target + 1) / 2\r\n",
        "    ssim_loss = 1 - ssim(input, target, data_range=1, size_average=size_average)\r\n",
        "    return ssim_loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpJsmaNXBrjx"
      },
      "source": [
        "# Flags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovVXOcHARgTp"
      },
      "source": [
        "import sys\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "device = torch.device('cuda:{}'.format(0))\n",
        "torch.cuda.set_device('cuda:{}'.format(0))\n",
        "MODE = 'wgan-gp'  # Valid options are dcgan, wgan, or wgan-gp\n",
        "DIM = 64  # This overfits substantially; you're probably better off with 64\n",
        "LAMBDA = 10  # Gradient penalty lambda hyperparameter\n",
        "CRITIC_ITERS = 5  # How many critic iterations per generator iteration\n",
        "BATCH_SIZE = batchsize  # Batch size\n",
        "ITERS = 100000  # How many generator iterations to train for\n",
        "OUTPUT_DIM = 1 * DIM * DIM  # Number of pixels in image (3*64*64)\n",
        "NOISE_SIZE = 512\n",
        "\n",
        "train_data_path = \"data/train/\"\n",
        "valid_data_path = \"data/valid/\"\n",
        "test_data_path = \"data/test/\"\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.determinstic = False\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdXhqA8KRz_G"
      },
      "source": [
        "def calc_gradient_penalty(netD, real_data, fake_data):\n",
        "    alpha = torch.rand(BATCH_SIZE, 1)\n",
        "    alpha = alpha.expand(BATCH_SIZE, int(real_data.nelement()/BATCH_SIZE)).contiguous()\n",
        "    alpha = alpha.view(BATCH_SIZE, 1, DIM, DIM)\n",
        "    alpha = alpha.to(device)\n",
        "\n",
        "    fake_data = fake_data.view(BATCH_SIZE, 1, DIM, DIM)\n",
        "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
        "\n",
        "    interpolates = interpolates.to(device)\n",
        "    interpolates.requires_grad_(True)\n",
        "\n",
        "    disc_interpolates = netD(interpolates)\n",
        "\n",
        "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=torch.ones(\n",
        "                                  disc_interpolates.size()).to(device),\n",
        "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
        "    return gradient_penalty"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux_cOKIaBvIp"
      },
      "source": [
        "# DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37O01eVmMnUH"
      },
      "source": [
        "def get_dataloaders(train_data_path, test_data_path, bs=batchsize):\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.RandomAffine(5, translate=[0.05,0.05]),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "    ])\n",
        "    \n",
        "    trn_dataset = datasets.ImageFolder(root=train_data_path, transform=test_transform)\n",
        "    tst_dataset = datasets.ImageFolder(root=test_data_path, transform=test_transform)\n",
        "\n",
        "    trn_loader = torch.utils.data.DataLoader(trn_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
        "    tst_loader = torch.utils.data.DataLoader(tst_dataset, batch_size=bs, shuffle=False)\n",
        "  \n",
        "    return trn_loader, tst_loader"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIk3JNRV28Fw"
      },
      "source": [
        "# PGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1--0gw512-jG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8751296b-c19b-4177-9479-5e794a9fdaf3"
      },
      "source": [
        "!git clone https://nitishbhatt56:@github.com/nitishbhatt56/pytorch_GAN_zoo.git"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pytorch_GAN_zoo' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDeyy26C25H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ad4da6-10fe-47da-9142-d86340645945"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/FYDP 2021/PGAN_p64_s4_96k.zip\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/FYDP 2021/PGAN_p64_s4_96k.zip\n",
            "replace output_networks/default/default_s3_i80000.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjwCiFCW3DMP"
      },
      "source": [
        "import pytorch_GAN_zoo.models.utils.utils as utils\r\n",
        "import json\r\n",
        "import sys\r\n",
        "sys.path.insert(0,'./pytorch_GAN_zoo')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9odjZbo4FcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa4d66e-80fe-4cfe-f661-66d80818e822"
      },
      "source": [
        "checkpt_dir = 'output_networks'\r\n",
        "name='default'\r\n",
        "checkPointDir = os.path.join(checkpt_dir, name)\r\n",
        "module = 'PGAN'\r\n",
        "\r\n",
        "checkpointData = utils.getLastCheckPoint(\r\n",
        "            checkPointDir, name, scale=None, iter=None)\r\n",
        "\r\n",
        "print(checkpointData)\r\n",
        "modelConfig, pathModel, _ = checkpointData\r\n",
        "with open(modelConfig, 'rb') as file:\r\n",
        "    configData = json.load(file)\r\n",
        "\r\n",
        "modelPackage, modelName = utils.getNameAndPackage(module)\r\n",
        "modelType = utils.loadmodule(modelPackage, modelName)\r\n",
        "\r\n",
        "model = modelType(useGPU=True,\r\n",
        "                  storeAVG=True,\r\n",
        "                  **configData)\r\n",
        "\r\n",
        "\r\n",
        "model.load(pathModel)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('output_networks/default/default_train_config.json', 'output_networks/default/default_s4_i96000.pt', 'output_networks/default/default_s4_i96000_tmp_config.json')\n",
            "Average network found !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeeHmkDyB0jW"
      },
      "source": [
        "# Encoder Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0yrXiuw-uuw"
      },
      "source": [
        "def calc_alpha(e):\r\n",
        "  if e < 75:\r\n",
        "      return 0.1\r\n",
        "  return 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "C45gpm_tSCAM"
      },
      "source": [
        "def train_encoder():\n",
        "    netG = model.avgG\n",
        "    netG.eval()\n",
        "    netD = model.netD\n",
        "    netD.eval()\n",
        "    for p in netD.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in netG.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    dataloader, validloader = get_dataloaders(train_data_path, valid_data_path, BATCH_SIZE)\n",
        "\n",
        "    netE = Encoder(DIM,NOISE_SIZE,0.3).to(device)\n",
        "    optimizer = optim.Adam(netE.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
        "    crit = nn.MSELoss()\n",
        "    rec_crit = nn.L1Loss()\n",
        "    \n",
        "    chkpts = os.listdir('encoder/')\n",
        "    if not chkpts: \n",
        "      print('starting from scratch...')\n",
        "      start_iter = 1\n",
        "    else:\n",
        "      print('loading checkpoint...')\n",
        "      chkpts = sorted(chkpts, reverse=True, key=lambda x : float(re.split('_|p',x)[1]))\n",
        "      checkpoint_fpathE = os.path.join('encoder/', chkpts[0])\n",
        "      print(checkpoint_fpathE)\n",
        "      checkpointEl = torch.load(checkpoint_fpathE)\n",
        "\n",
        "      netE.load_state_dict(checkpointEl['state_dict'])\n",
        "      optimizer.load_state_dict(checkpointEl['optimizer'])\n",
        "\n",
        "      start_iter = checkpointEl['epoch']\n",
        "\n",
        "    for e in range(start_iter, 300):\n",
        "        losses = []\n",
        "        netE.train()\n",
        "        options_alpha = calc_alpha(e)\n",
        "        for (x, _) in dataloader:\n",
        "            x = x.to(device)\n",
        "            code = netE(x)\n",
        "            rec_image = netG(code)\n",
        "            code_rec = netE(rec_image)\n",
        "            f_x = netD.forward(x,getFeature=True)[1].detach()\n",
        "            f_gx = netD.forward(rec_image,getFeature=True)[1]\n",
        "            loss = ssim_loss(rec_image, x) + rec_crit(code_rec, code) + options_alpha * rec_crit(f_gx, f_x)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        print(e, np.mean(losses))\n",
        "        netE.eval()\n",
        "        rec_image = netG(netE(x))\n",
        "        d_input = torch.cat((x, rec_image), dim=0)\n",
        "        save_image(d_input, 'rec'+str(e)+'.jpg',normalize=True)\n",
        "        if e % 1 == 0:\n",
        "            checkpointE = {\n",
        "              'epoch': e + 1,\n",
        "              'state_dict': netE.state_dict(),\n",
        "              'optimizer': optimizer.state_dict()\n",
        "            }\n",
        "            torch.save(checkpointE, 'encoder/netE_%d.pth' % e)\n",
        "            evaluate(netG, netD, netE,options_alpha,validloader)\n",
        "            shutil.copy('encoder/netE_%d.pth' % e,'/content/drive/MyDrive/FYDP 2021/ANOGAN-Weights/PanoGAN/encoder/running/netE_%d.pth' % e)\n",
        "    torch.save(netE.state_dict(), 'wgangp/netE.pth')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YvmUl5VB4vS"
      },
      "source": [
        "# Evaluate Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZPh4qDKSKkR"
      },
      "source": [
        "def evaluate(netG, netD, netE,options_alpha, dataloader):\n",
        "    options_c = 0\n",
        "    netE.eval()\n",
        "    netD.eval()\n",
        "    netE.eval()\n",
        "\n",
        "    # crit = nn.MSELoss()\n",
        "    y_true, y_score = [], []\n",
        "    rec_scores, enc_scores, feat_scores = [], [], []\n",
        "    in_real, out_real, in_rec, out_rec = [], [], [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (x, label) in dataloader:\n",
        "            bs = x.size(0)\n",
        "            x = x.to(device)\n",
        "            code = netE(x)\n",
        "            rec_image = netG(code)\n",
        "            rec_code = netE(rec_image)\n",
        "\n",
        "            d_input = torch.cat((x, rec_image), dim=0)\n",
        "            idx = (label == options_c)\n",
        "            in_real.append(x[idx])\n",
        "            in_rec.append(rec_image[idx])\n",
        "            idx = (label != options_c)\n",
        "            out_real.append(x[idx])\n",
        "            out_rec.append(rec_image[idx])\n",
        "            # f_x = netD.forward(x,getFeature=True)[1]\n",
        "            # f_gx = netD.forward(rec_image,getFeature=True)[1]\n",
        "            \n",
        "            rec_diff = torch.abs((rec_image.view(bs, -1) - x.view(bs, -1)))\n",
        "            rec_score = rec_diff.mean(dim=1)\n",
        "            # rec_score = ssim_loss(rec_image, x,size_average=False)\n",
        "            rec_scores.append(rec_score.cpu().numpy())\n",
        "\n",
        "            enc_diff = torch.abs((rec_code-code))\n",
        "            #enc_score = enc_diff.mean(dim=1)\n",
        "            enc_scores.append(enc_diff.mean(dim=1).cpu().numpy())\n",
        "\n",
        "            # feat_diff = ((f_x - f_gx)**2)\n",
        "            # feat_score = feat_diff.mean(dim=1) \n",
        "            #feat_scores.append(feat_diff.mean(dim=1).cpu().numpy())\n",
        "\n",
        "            #plt.figure()\n",
        "            #plt.imshow(x[0,0].cpu())\n",
        "            #print(outlier_score.cpu().numpy())\n",
        "            # outlier_score = ssim_loss(rec_image, x, size_average=False)\n",
        "            y_true.append(label)\n",
        "            # y_score.append(outlier_score.cpu())\n",
        "\n",
        "    enc_scores = np.concatenate(enc_scores)\n",
        "    rec_scores = np.concatenate(rec_scores)\n",
        "    #feat_scores = np.concatenate(feat_scores)\n",
        "    rec_scores = (rec_scores - np.min(rec_scores)) / (np.max(rec_scores) - np.min(rec_scores))\n",
        "    #feat_score = (feat_scores - np.min(feat_scores)) / (np.max(feat_scores) - np.min(feat_scores))\n",
        "    enc_scores = (enc_scores - np.min(enc_scores)) / (np.max(enc_scores) - np.min(enc_scores))\n",
        "\n",
        "    y_score = rec_scores + enc_scores #+ feat_scores\n",
        "\n",
        "    in_real = torch.cat(in_real, dim=0)[:32]\n",
        "    in_rec = torch.cat(in_rec, dim=0)[:32]\n",
        "    out_real = torch.cat(out_real, dim=0)[:32]\n",
        "    out_rec = torch.cat(out_rec, dim=0)[:32]\n",
        "    save_image(torch.cat((in_real, in_rec), dim=0), 'healthy.jpg', normalize=True)\n",
        "    save_image(torch.cat((out_real, out_rec), dim=0),\n",
        "               'unhealthy.jpg', normalize=True)\n",
        "    # y_score = np.concatenate(y_score)\n",
        "    y_true = np.concatenate(y_true)\n",
        "    y_true[y_true != options_c] = -1\n",
        "    y_true[y_true == options_c] = 1\n",
        "    print('auc:', metrics.roc_auc_score(y_true, -y_score))\n",
        "    #plt.figure()\n",
        "    #plt.hist(y_score[y_true==1], 100, density=True, alpha=0.5, color='blue')\n",
        "    #plt.hist(y_score[y_true==-1], 100, density=True, alpha=0.5, color='red')\n",
        "    #plt.show()\n",
        "    return y_true, y_score"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iut7K6lz3sVQ"
      },
      "source": [
        "# Test Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAHGTIZYcKQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928f7cda-da9a-429a-9d20-244fb7172396"
      },
      "source": [
        "!pip install kornia"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kornia) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.7.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->kornia) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZfLRwNz_dIu"
      },
      "source": [
        "from kornia import gaussian_blur2d, median_blur"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcxAXuQyGYFT"
      },
      "source": [
        "def test(path):\r\n",
        "    options_alpha = 1\r\n",
        "    options_c = 0\r\n",
        "    netG = model.avgG\r\n",
        "    netG.eval()\r\n",
        "    netD = model.netD\r\n",
        "    netD.eval()\r\n",
        "    for p in netD.parameters():\r\n",
        "        p.requires_grad = False\r\n",
        "    for p in netG.parameters():\r\n",
        "        p.requires_grad = False\r\n",
        "\r\n",
        "    netE = Encoder(DIM,NOISE_SIZE).to(device)\r\n",
        "    optimizer = optim.Adam(netE.parameters(), lr=1e-4, betas=(0., 0.9),weight_decay=1e-5)\r\n",
        "    crit = nn.MSELoss()\r\n",
        "    rec_crit = nn.MSELoss()\r\n",
        "    \r\n",
        "    chkpts = os.listdir('encoder/')\r\n",
        "    if not chkpts: \r\n",
        "      print('starting from scratch...')\r\n",
        "      start_iter = 1\r\n",
        "    else:\r\n",
        "      print('loading checkpoint...')\r\n",
        "      chkpts = sorted(chkpts, reverse=True, key=lambda x : float(re.split('_|p',x)[1]))\r\n",
        "      checkpoint_fpathE = os.path.join('encoder/', chkpts[0])\r\n",
        "      print(checkpoint_fpathE)\r\n",
        "      checkpointEl = torch.load(checkpoint_fpathE)\r\n",
        "\r\n",
        "      netE.load_state_dict(checkpointEl['state_dict'])\r\n",
        "      optimizer.load_state_dict(checkpointEl['optimizer'])\r\n",
        "\r\n",
        "      start_iter = checkpointEl['epoch']\r\n",
        "    \r\n",
        "    netE.eval()\r\n",
        "    _, dataloader = get_dataloaders(train_data_path, path, BATCH_SIZE)\r\n",
        "    # crit = nn.MSELoss()\r\n",
        "    y_true, y_score = [], []\r\n",
        "    in_real, out_real, in_rec, out_rec = [], [], [], []\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        for (x, label) in dataloader:\r\n",
        "            bs = x.size(0)\r\n",
        "            x = x.to(device)\r\n",
        "            # denoise\r\n",
        "            x = median_blur(x,(5,5))\r\n",
        "            code = netE(x)\r\n",
        "            rec_image = netG(code)\r\n",
        "            rec_code = netE(rec_image)\r\n",
        "            # rec_image = median_blur(rec_image,(5,5))\r\n",
        "            d_input = torch.cat((x, rec_image), dim=0)\r\n",
        "            idx = (label == options_c)\r\n",
        "            in_real.append(x[idx])\r\n",
        "            in_rec.append(rec_image[idx])\r\n",
        "            idx = (label != options_c)\r\n",
        "            out_real.append(x[idx])\r\n",
        "            out_rec.append(rec_image[idx])\r\n",
        "            f_x = netD.forward(x,getFeature=True)[1]\r\n",
        "            f_gx = netD.forward(rec_image,getFeature=True)[1]\r\n",
        "\r\n",
        "            rec_diff = abs((rec_image.view(bs, -1) - x.view(bs, -1)))\r\n",
        "            rec_score = rec_diff.mean(dim=1) \r\n",
        "            rec_score = rec_score + ssim_loss(rec_image, x, size_average=False)\r\n",
        "            feat_diff = ((f_x - f_gx)**2)\r\n",
        "            feat_score = feat_diff.mean(dim=1) \r\n",
        "            enc_score =((rec_code - code)**2)\r\n",
        "            enc_score = enc_score.mean(dim=1)\r\n",
        "            outlier_score = rec_score + options_alpha * feat_score\r\n",
        "            # outlier_score = rec_score + enc_score\r\n",
        "            #plt.figure()\r\n",
        "            #plt.imshow(x[0,0].cpu())\r\n",
        "            #print(outlier_score.cpu().numpy())\r\n",
        "            # outlier_score = ssim_loss(rec_image, x, size_average=False)\r\n",
        "            y_true.append(label)\r\n",
        "            y_score.append(outlier_score.cpu())\r\n",
        "    in_real = torch.cat(in_real, dim=0)[:32]\r\n",
        "    in_rec = torch.cat(in_rec, dim=0)[:32]\r\n",
        "    out_real = torch.cat(out_real, dim=0)[:32]\r\n",
        "    out_rec = torch.cat(out_rec, dim=0)[:32]\r\n",
        "    save_image(torch.cat((in_real, in_rec), dim=0), 'test-healthy.jpg', normalize=True)\r\n",
        "    save_image(torch.cat((out_real, out_rec), dim=0),\r\n",
        "               'test-unhealthy.jpg', normalize=True)\r\n",
        "    y_score = np.concatenate(y_score)\r\n",
        "    y_true = np.concatenate(y_true)\r\n",
        "    y_true[y_true != options_c] = -1\r\n",
        "    y_true[y_true == options_c] = 1\r\n",
        "    print('auc:', metrics.roc_auc_score(y_true, -y_score))\r\n",
        "    plt.figure()\r\n",
        "    plt.hist(y_score[y_true==1], 100, density=True, alpha=0.5, color='blue')\r\n",
        "    plt.hist(y_score[y_true==-1], 100, density=True, alpha=0.5, color='red')\r\n",
        "    plt.show()\r\n",
        "    return y_true, y_score"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PizW8E4VB66l"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGqUu9xyVyCP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d395d6bb-4bcb-46db-d559-0f93f4531708"
      },
      "source": [
        "options_eval = False\n",
        "options_stage = 2\n",
        "if not options_eval:\n",
        "    if options_stage == 1:\n",
        "        wgan_training()\n",
        "    elif options_stage == 2:\n",
        "        train_encoder()\n",
        "else:\n",
        "    y_true, y_score = evaluate()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting from scratch...\n",
            "1 0.5656719654798508\n",
            "auc: 0.7506576903476001\n",
            "2 0.5312511258325784\n",
            "auc: 0.7525768147126747\n",
            "3 0.5255871087743835\n",
            "auc: 0.7490660720543965\n",
            "4 0.5207254160970288\n",
            "auc: 0.7430163921380177\n",
            "5 0.5184206461389069\n",
            "auc: 0.773708608359363\n",
            "6 0.5144745157004265\n",
            "auc: 0.7679604176773698\n",
            "7 0.5106285374483622\n",
            "auc: 0.7487370355803209\n",
            "8 0.5091016926073467\n",
            "auc: 0.6981373474762902\n",
            "9 0.5067045814197706\n",
            "auc: 0.7390358160028038\n",
            "10 0.5045829396998042\n",
            "auc: 0.7001284007449997\n",
            "11 0.502275385730521\n",
            "auc: 0.6981327562696753\n",
            "12 0.5009242870439026\n",
            "auc: 0.6827659877292351\n",
            "13 0.49863266917939214\n",
            "auc: 0.6971808460981631\n",
            "14 0.49716692562021353\n",
            "auc: 0.685341654640256\n",
            "15 0.49535241520965295\n",
            "auc: 0.6837469755426424\n",
            "16 0.4935259596995376\n",
            "auc: 0.675256304109283\n",
            "17 0.492031117729425\n",
            "auc: 0.6898777667758864\n",
            "18 0.4908550022200262\n",
            "auc: 0.6630467553177651\n",
            "19 0.4893766271108745\n",
            "auc: 0.6967584550895822\n",
            "20 0.48815156088276324\n",
            "auc: 0.6611352829637157\n",
            "21 0.48709799424756933\n",
            "auc: 0.694253951881094\n",
            "22 0.48543714420704903\n",
            "auc: 0.704154888946364\n",
            "23 0.4845370156909415\n",
            "auc: 0.6753435370349681\n",
            "24 0.4833380424200303\n",
            "auc: 0.6752425304894379\n",
            "25 0.48268326847505827\n",
            "auc: 0.697130342825398\n",
            "26 0.4815710081060368\n",
            "auc: 0.6738085436233496\n",
            "27 0.48067381991507996\n",
            "auc: 0.6847172505406146\n",
            "28 0.48017444258141473\n",
            "auc: 0.6835005807876369\n",
            "29 0.4789268961327848\n",
            "auc: 0.6851381111469905\n",
            "30 0.4782212186624948\n",
            "auc: 0.6614765626554314\n",
            "31 0.47766318874160807\n",
            "auc: 0.6663799713202627\n",
            "32 0.4767389525179406\n",
            "auc: 0.6841004984519982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-86e0f206996e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mwgan_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moptions_stage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-d5f3631b25fe>\u001b[0m in \u001b[0;36mtrain_encoder\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptions_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mrec_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpMM_P_Hkm8"
      },
      "source": [
        "!rm -r encoder/\r\n",
        "!mkdir encoder/\r\n",
        "\r\n",
        "for img in os.listdir(\"./\"):\r\n",
        "  if img[-3:] == \"jpg\":\r\n",
        "    os.remove(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pntPoBU0HNa"
      },
      "source": [
        "test(valid_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}